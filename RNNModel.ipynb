{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "c2b565d5",
      "metadata": {
        "id": "c2b565d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "07983152",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07983152",
        "outputId": "13781432-4407-4743-9d60-e7f782136338"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\tranx\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\tranx\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\tranx\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# This function use regex and nltk to tokenize sentnece, remove stopwords and rejoined sentence again\n",
        "# Input: A sentence (or an instance in a training data)\n",
        "# Output: Cleaned sentence\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    clean_sentence = ' '.join(tokens)\n",
        "    return clean_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "51c0c7b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Read csv and target the text for preprocessing\n",
        "df_train = pd.read_csv(\"trac2_CONVT_train.csv\")\n",
        "columnsTrain = df_train[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "5025b227",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This cell prepare token for preprocessing data in each sentence\n",
        "# 1. Every sentence needs to start with <SOS> (Start of Sentence) token\n",
        "# 2. Every sentence needs to end with <EOS> (End of Sentence) token\n",
        "# 3. Every sentence needs to have the same length for training. Find the longest\n",
        "#    sentence, store the length into a variable. Then pad all the remaining \n",
        "#    sentence with <PAD> token to ensure every other sentence has the same length\n",
        "#    as the longest one\n",
        "# 4. If words is not in the training sentence vocab, assign it with <UNK> token\n",
        "PAD_TOKEN = \"<PAD>\"\n",
        "EOS_TOKEN = \"<EOS>\"\n",
        "SOS_TOKEN = \"<SOS>\"\n",
        "UNK_TOKEN = \"<UNK>\"\n",
        "listToken = [PAD_TOKEN, EOS_TOKEN, SOS_TOKEN, UNK_TOKEN]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "522b390b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "522b390b",
        "outputId": "6ef17a92-05e2-4212-97fc-7585fa61f9dc"
      },
      "outputs": [],
      "source": [
        "# This cell build training vocab (include both 4 tokens from above)\n",
        "# This cell also change the sentence into list of word that are used to build the vector later\n",
        "\n",
        "emotionVocab = set()\n",
        "listSentence = []\n",
        "listWordVectorTrain = []\n",
        "maxLengthSentence = 0\n",
        "\n",
        "\n",
        "for column in columnsTrain:\n",
        "    cleanColumn = clean_text(column)\n",
        "    listSentence.append(cleanColumn)\n",
        "\n",
        "for sentence in listSentence:\n",
        "    listWord = sentence.split(\" \")\n",
        "    if \"\" in listWord:\n",
        "        listWord.remove(\"\")\n",
        "    if len(listWord) > maxLengthSentence:\n",
        "        maxLengthSentence = len(listWord)\n",
        "\n",
        "    listWordVectorTrain.append(listWord)\n",
        "    for word in listWord:\n",
        "        emotionVocab.add(word)\n",
        "\n",
        "\n",
        "\n",
        "emotionVocabList = list(emotionVocab) + listToken\n",
        "sortedVocab = sorted(emotionVocabList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "12280f3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12280f3d",
        "outputId": "f8f585bd-8c1a-4fed-cca4-6a6b1b9b9067"
      },
      "outputs": [],
      "source": [
        "# This function padding all the sentence in the training corpus to have the same length\n",
        "# as the longest sentence (127 in this case)\n",
        "\n",
        "def padSentence(listWordVector):\n",
        "    listSentencePad = []\n",
        "    for wordVector in listWordVector:\n",
        "        paddedWordVector = [SOS_TOKEN] + wordVector + ([PAD_TOKEN] * (maxLengthSentence - len(wordVector))) + [EOS_TOKEN]\n",
        "        listSentencePad.append(paddedWordVector)\n",
        "    return listSentencePad\n",
        "\n",
        "listSentencePadTrain = padSentence(listWordVectorTrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "3230eda2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3230eda2",
        "outputId": "d239df0e-ef6e-4a56-f490-85279fb7b2fc"
      },
      "outputs": [],
      "source": [
        "# Building dictionary that convert English words to integer in the training corpus vocab\n",
        "# Output: {'<EOS>': 0, '<PAD>': 1, '<SOS>': 2, '<UNK>': 3, 'a': 4, 'abalone': 5, 'abandon': 6, 'abandoned': 7, \n",
        "# 'abdicated': 8, 'abdomen': 9, 'abe': 10, 'abilities': 11, 'ability': 12,...}\n",
        "\n",
        "eng_word2int = {word: i for i, word in enumerate(sortedVocab)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "b5738987",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5738987",
        "outputId": "6b0a6518-5a69-4bda-a9ba-cacd07ae133e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   2 9623 2335 9873 8778   18 8789  533    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    0]\n"
          ]
        }
      ],
      "source": [
        "# Building tensor with the dictionary eng_word2int and padded corpus\n",
        "# The output will be a wordTensor where each word has an integer value correctsponding to the dictionary\n",
        "\n",
        "import numpy as np\n",
        "def convertToTensor(listSentencePad):\n",
        "    wordTensor = []\n",
        "    for listSentence in listSentencePad:\n",
        "        numericArray = []\n",
        "        for word in listSentence:\n",
        "            if word in eng_word2int:\n",
        "                numericArray.append(eng_word2int[word])\n",
        "            else:\n",
        "                numericArray.append(3)\n",
        "        wordTensor.append(np.array(numericArray))\n",
        "    return wordTensor\n",
        "    \n",
        "wordTensorTrain = convertToTensor(listSentencePadTrain)\n",
        "X_train = np.array(wordTensorTrain)\n",
        "print(wordTensorTrain[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "579a0b87",
      "metadata": {},
      "outputs": [],
      "source": [
        "# For this task, I am using Glove for word embedding tasks\n",
        "# The Glove file can be download in https://nlp.stanford.edu/projects/glove/\n",
        "# I am using \"glove.6B.300d.txt\", meaning each words will be represented as 300 dimensional vectors\n",
        "# The cell below build the hashmap to encode word with their correctsponding vector from the Glove file\n",
        "# Input: glove.6B.300d.txt\n",
        "# Output: Hashmap look like this form:\n",
        "# embedding_index = { \"a\": [2 4 5 1 2 4 5 ...],\n",
        "#                     \"an\": [3 1 3 5 1 2 4 ...],...}\n",
        "# (Each list has 300 values since it represent 300 dimensions)\n",
        "\n",
        "\n",
        "embedding_dim = 300\n",
        "embedding_index = {}\n",
        "with open(\"glove.6B.300d.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype=\"float32\")\n",
        "        embedding_index[word] = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "1488951f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Building an embedding matrix for the training task\n",
        "# The embedding matrix will have around 10000 rows (the number of unique words in training vocab) x 300 dimensions\n",
        "# This embedding matrix will have the form like this:\n",
        "# [[0 0 0 0 0 0 0 ...], -> 300d vector represents PAD_TOKEN (initialize to 0 vector)\n",
        "#  [0 0 0 0 0 0 0 ...], -> 300d vector represents EOS_TOKEN (initialize to 0 vector)\n",
        "#  [0 0 0 0 0 0 0 ...], -> 300d vector represents SOS_TOKEN (initialize to 0 vector)\n",
        "#  [1 3 1 2 3 1 2 ...], -> 300d vector represents UNK_TOKEN (initialize to a random vector)\n",
        "#  [...],\n",
        "#  [1 2 3 1 2 3 1 ...]] -> 300d vector represents PAD_TOKEN (initialize to represented i-th words in vocab)\n",
        "\n",
        "embedding_matrix = np.zeros((len(sortedVocab), embedding_dim))\n",
        "for word, idx in eng_word2int.items():\n",
        "    vector = embedding_index.get(word)\n",
        "    if vector is not None:\n",
        "        embedding_matrix[idx] = vector\n",
        "    elif word == PAD_TOKEN or word == SOS_TOKEN or word == EOS_TOKEN:\n",
        "        embedding_matrix[idx] = np.zeros(shape=(embedding_dim,))\n",
        "    elif word == UNK_TOKEN :\n",
        "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "2cc1b6a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cc1b6a0",
        "outputId": "c55886ed-079c-4d8e-ef6d-cca802b501ea"
      },
      "outputs": [],
      "source": [
        "# This cell build the output (Y_output) for any dataframe\n",
        "# Output of regression task: Emotion Intensity (From 0-5 in ordinal scale) and Emphathy Intensity (0-5 in ordinal scale)\n",
        "# Output of classficiation task: Emotional Polarity (0, 1, 2). 0 is positive, 1 is neutral and 2 is negative\n",
        "from numpy import unique\n",
        "\n",
        "def processOutput(df):\n",
        "    emotionColumnIndex = df.columns.get_loc(\"Emotion\")\n",
        "    emotionPolarityColumnIndex = df.columns.get_loc(\"EmotionalPolarity\")\n",
        "    emphathyColumnIndex = df.columns.get_loc(\"Empathy\")\n",
        "\n",
        "    Y_reg = []\n",
        "    Y_class = []\n",
        "    instance = []\n",
        "\n",
        "    for i in range(0, len(df)):\n",
        "        instance.append(df.iloc[i, emotionColumnIndex])\n",
        "        instance.append(df.iloc[i, emphathyColumnIndex])\n",
        "        Y_reg.append(instance)\n",
        "        instance = []\n",
        "\n",
        "    for i in range(0, len(df)):\n",
        "        instance.append(df.iloc[i, emotionPolarityColumnIndex])\n",
        "        Y_class.append(instance)\n",
        "        instance = []\n",
        "\n",
        "    return np.array(Y_reg), np.array(Y_class)\n",
        "\n",
        "Y_train_reg, Y_train_class = processOutput(df_train)\n",
        "nClass = len(unique(Y_train_class))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "387814e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "387814e4",
        "outputId": "73f8272d-736d-425e-c86b-7683b6254ffb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\CS 421 - Project 1\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "inputs = Input(shape=(len(wordTensorTrain[0]),))\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    input_dim = len(sortedVocab),\n",
        "    output_dim = embedding_dim,\n",
        "    embeddings_initializer = Constant(embedding_matrix),\n",
        "    input_length = len(wordTensorTrain[0]),\n",
        "    trainable=True,\n",
        ")(inputs)\n",
        "\n",
        "lstmLayers = LSTM(128, activation='tanh', dropout = 0.2)(embedding_layer)\n",
        "batchNormalizeLayer = BatchNormalization()(lstmLayers)\n",
        "regression_output = Dense(2, name='regression')(batchNormalizeLayer)\n",
        "\n",
        "classification_output = Dense(nClass, activation = 'softmax', name='classification')(batchNormalizeLayer)\n",
        "\n",
        "modelNLP = Model(inputs = inputs, outputs=[regression_output, classification_output])\n",
        "\n",
        "modelNLP.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss={\n",
        "        'regression': 'mse',\n",
        "        'classification': 'categorical_crossentropy'\n",
        "    },\n",
        "    metrics={\n",
        "        'regression': ['mse'],\n",
        "        'classification': ['accuracy']\n",
        "    }\n",
        ")\n",
        "\n",
        "plot_model(modelNLP, to_file='model.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jYwVw7On8ogU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYwVw7On8ogU",
        "outputId": "d17c3d07-e526-471b-c001-1f41da8b2f95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9280 - classification_loss: 0.2147 - loss: 0.6263 - regression_loss: 0.4115 - regression_mse: 0.4116 - val_classification_accuracy: 0.6019 - val_classification_loss: 1.5962 - val_loss: 2.3131 - val_regression_loss: 0.7366 - val_regression_mse: 0.7361\n",
            "Epoch 2/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9439 - classification_loss: 0.1775 - loss: 0.5883 - regression_loss: 0.4107 - regression_mse: 0.4108 - val_classification_accuracy: 0.6109 - val_classification_loss: 1.5582 - val_loss: 2.2538 - val_regression_loss: 0.7101 - val_regression_mse: 0.7104\n",
            "Epoch 3/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9413 - classification_loss: 0.1822 - loss: 0.5901 - regression_loss: 0.4079 - regression_mse: 0.4079 - val_classification_accuracy: 0.6096 - val_classification_loss: 1.5488 - val_loss: 2.2377 - val_regression_loss: 0.7046 - val_regression_mse: 0.7060\n",
            "Epoch 4/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9348 - classification_loss: 0.1852 - loss: 0.5952 - regression_loss: 0.4100 - regression_mse: 0.4100 - val_classification_accuracy: 0.6199 - val_classification_loss: 1.5610 - val_loss: 2.2409 - val_regression_loss: 0.6958 - val_regression_mse: 0.6973\n",
            "Epoch 5/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9478 - classification_loss: 0.1615 - loss: 0.5679 - regression_loss: 0.4064 - regression_mse: 0.4064 - val_classification_accuracy: 0.6222 - val_classification_loss: 1.6240 - val_loss: 2.3035 - val_regression_loss: 0.6877 - val_regression_mse: 0.6890\n",
            "Epoch 6/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9495 - classification_loss: 0.1574 - loss: 0.5626 - regression_loss: 0.4051 - regression_mse: 0.4052 - val_classification_accuracy: 0.6357 - val_classification_loss: 1.6465 - val_loss: 2.3407 - val_regression_loss: 0.6996 - val_regression_mse: 0.7016\n",
            "Epoch 7/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9522 - classification_loss: 0.1500 - loss: 0.5512 - regression_loss: 0.4012 - regression_mse: 0.4012 - val_classification_accuracy: 0.6231 - val_classification_loss: 1.6544 - val_loss: 2.3388 - val_regression_loss: 0.6916 - val_regression_mse: 0.6929\n",
            "Epoch 8/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9554 - classification_loss: 0.1410 - loss: 0.5364 - regression_loss: 0.3953 - regression_mse: 0.3953 - val_classification_accuracy: 0.6226 - val_classification_loss: 1.7304 - val_loss: 2.4207 - val_regression_loss: 0.6946 - val_regression_mse: 0.6961\n",
            "Epoch 9/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9584 - classification_loss: 0.1379 - loss: 0.5298 - regression_loss: 0.3920 - regression_mse: 0.3920 - val_classification_accuracy: 0.6159 - val_classification_loss: 1.7245 - val_loss: 2.4252 - val_regression_loss: 0.7030 - val_regression_mse: 0.7049\n",
            "Epoch 10/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9607 - classification_loss: 0.1285 - loss: 0.5174 - regression_loss: 0.3889 - regression_mse: 0.3889 - val_classification_accuracy: 0.6114 - val_classification_loss: 1.8475 - val_loss: 2.5515 - val_regression_loss: 0.7059 - val_regression_mse: 0.7079\n",
            "Epoch 11/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9629 - classification_loss: 0.1259 - loss: 0.5153 - regression_loss: 0.3894 - regression_mse: 0.3894 - val_classification_accuracy: 0.6114 - val_classification_loss: 1.8684 - val_loss: 2.5734 - val_regression_loss: 0.7082 - val_regression_mse: 0.7087\n",
            "Epoch 12/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9663 - classification_loss: 0.1150 - loss: 0.4998 - regression_loss: 0.3848 - regression_mse: 0.3848 - val_classification_accuracy: 0.6078 - val_classification_loss: 1.8374 - val_loss: 2.5472 - val_regression_loss: 0.7151 - val_regression_mse: 0.7155\n",
            "Epoch 13/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9668 - classification_loss: 0.1155 - loss: 0.4988 - regression_loss: 0.3833 - regression_mse: 0.3833 - val_classification_accuracy: 0.6105 - val_classification_loss: 1.9183 - val_loss: 2.6072 - val_regression_loss: 0.6957 - val_regression_mse: 0.6968\n",
            "Epoch 14/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9635 - classification_loss: 0.1223 - loss: 0.5037 - regression_loss: 0.3814 - regression_mse: 0.3814 - val_classification_accuracy: 0.6014 - val_classification_loss: 1.8713 - val_loss: 2.5788 - val_regression_loss: 0.7088 - val_regression_mse: 0.7101\n",
            "Epoch 15/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9665 - classification_loss: 0.1126 - loss: 0.4895 - regression_loss: 0.3769 - regression_mse: 0.3769 - val_classification_accuracy: 0.5978 - val_classification_loss: 1.9436 - val_loss: 2.6521 - val_regression_loss: 0.7090 - val_regression_mse: 0.7100\n",
            "Epoch 16/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9657 - classification_loss: 0.1144 - loss: 0.4923 - regression_loss: 0.3779 - regression_mse: 0.3779 - val_classification_accuracy: 0.6041 - val_classification_loss: 1.9296 - val_loss: 2.6319 - val_regression_loss: 0.7020 - val_regression_mse: 0.7026\n",
            "Epoch 17/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9597 - classification_loss: 0.1214 - loss: 0.4995 - regression_loss: 0.3781 - regression_mse: 0.3781 - val_classification_accuracy: 0.5757 - val_classification_loss: 1.7815 - val_loss: 2.5007 - val_regression_loss: 0.7187 - val_regression_mse: 0.7190\n",
            "Epoch 18/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9583 - classification_loss: 0.1314 - loss: 0.5184 - regression_loss: 0.3870 - regression_mse: 0.3870 - val_classification_accuracy: 0.6014 - val_classification_loss: 1.8058 - val_loss: 2.5198 - val_regression_loss: 0.7124 - val_regression_mse: 0.7141\n",
            "Epoch 19/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9659 - classification_loss: 0.1239 - loss: 0.4991 - regression_loss: 0.3752 - regression_mse: 0.3752 - val_classification_accuracy: 0.5974 - val_classification_loss: 1.8345 - val_loss: 2.5472 - val_regression_loss: 0.7140 - val_regression_mse: 0.7154\n",
            "Epoch 20/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9707 - classification_loss: 0.1035 - loss: 0.4741 - regression_loss: 0.3706 - regression_mse: 0.3706 - val_classification_accuracy: 0.5983 - val_classification_loss: 2.0335 - val_loss: 2.7616 - val_regression_loss: 0.7252 - val_regression_mse: 0.7266\n",
            "Epoch 21/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9678 - classification_loss: 0.1113 - loss: 0.4761 - regression_loss: 0.3648 - regression_mse: 0.3648 - val_classification_accuracy: 0.6046 - val_classification_loss: 1.8822 - val_loss: 2.5802 - val_regression_loss: 0.7047 - val_regression_mse: 0.7058\n",
            "Epoch 22/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9723 - classification_loss: 0.0981 - loss: 0.4566 - regression_loss: 0.3586 - regression_mse: 0.3586 - val_classification_accuracy: 0.6091 - val_classification_loss: 1.9608 - val_loss: 2.6992 - val_regression_loss: 0.7373 - val_regression_mse: 0.7397\n",
            "Epoch 23/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9678 - classification_loss: 0.1030 - loss: 0.4620 - regression_loss: 0.3589 - regression_mse: 0.3589 - val_classification_accuracy: 0.6041 - val_classification_loss: 1.9314 - val_loss: 2.6519 - val_regression_loss: 0.7223 - val_regression_mse: 0.7241\n",
            "Epoch 24/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9713 - classification_loss: 0.0962 - loss: 0.4492 - regression_loss: 0.3530 - regression_mse: 0.3531 - val_classification_accuracy: 0.5884 - val_classification_loss: 2.0642 - val_loss: 2.7999 - val_regression_loss: 0.7329 - val_regression_mse: 0.7339\n",
            "Epoch 25/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9689 - classification_loss: 0.1012 - loss: 0.4551 - regression_loss: 0.3539 - regression_mse: 0.3539 - val_classification_accuracy: 0.5951 - val_classification_loss: 2.0296 - val_loss: 2.7684 - val_regression_loss: 0.7368 - val_regression_mse: 0.7374\n",
            "Epoch 26/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9765 - classification_loss: 0.0857 - loss: 0.4358 - regression_loss: 0.3501 - regression_mse: 0.3501 - val_classification_accuracy: 0.5766 - val_classification_loss: 2.1811 - val_loss: 2.9306 - val_regression_loss: 0.7490 - val_regression_mse: 0.7498\n",
            "Epoch 27/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9737 - classification_loss: 0.0952 - loss: 0.4448 - regression_loss: 0.3496 - regression_mse: 0.3496 - val_classification_accuracy: 0.5893 - val_classification_loss: 2.0391 - val_loss: 2.7901 - val_regression_loss: 0.7478 - val_regression_mse: 0.7496\n",
            "Epoch 28/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9728 - classification_loss: 0.0990 - loss: 0.4453 - regression_loss: 0.3464 - regression_mse: 0.3464 - val_classification_accuracy: 0.5956 - val_classification_loss: 2.0199 - val_loss: 2.7593 - val_regression_loss: 0.7388 - val_regression_mse: 0.7412\n",
            "Epoch 29/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9693 - classification_loss: 0.0993 - loss: 0.4409 - regression_loss: 0.3416 - regression_mse: 0.3416 - val_classification_accuracy: 0.6114 - val_classification_loss: 1.9508 - val_loss: 2.6843 - val_regression_loss: 0.7298 - val_regression_mse: 0.7322\n",
            "Epoch 30/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9704 - classification_loss: 0.1046 - loss: 0.4525 - regression_loss: 0.3478 - regression_mse: 0.3479 - val_classification_accuracy: 0.6136 - val_classification_loss: 1.9998 - val_loss: 2.7578 - val_regression_loss: 0.7578 - val_regression_mse: 0.7607\n",
            "Epoch 31/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9750 - classification_loss: 0.0934 - loss: 0.4340 - regression_loss: 0.3406 - regression_mse: 0.3406 - val_classification_accuracy: 0.6118 - val_classification_loss: 1.9777 - val_loss: 2.7295 - val_regression_loss: 0.7524 - val_regression_mse: 0.7550\n",
            "Epoch 32/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9732 - classification_loss: 0.0923 - loss: 0.4314 - regression_loss: 0.3391 - regression_mse: 0.3391 - val_classification_accuracy: 0.6046 - val_classification_loss: 1.9829 - val_loss: 2.7210 - val_regression_loss: 0.7374 - val_regression_mse: 0.7399\n",
            "Epoch 33/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9728 - classification_loss: 0.0942 - loss: 0.4316 - regression_loss: 0.3374 - regression_mse: 0.3374 - val_classification_accuracy: 0.6069 - val_classification_loss: 1.9753 - val_loss: 2.7547 - val_regression_loss: 0.7762 - val_regression_mse: 0.7786\n",
            "Epoch 34/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9764 - classification_loss: 0.0861 - loss: 0.4199 - regression_loss: 0.3339 - regression_mse: 0.3339 - val_classification_accuracy: 0.6136 - val_classification_loss: 2.0285 - val_loss: 2.7842 - val_regression_loss: 0.7542 - val_regression_mse: 0.7575\n",
            "Epoch 35/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9754 - classification_loss: 0.0879 - loss: 0.4171 - regression_loss: 0.3292 - regression_mse: 0.3292 - val_classification_accuracy: 0.6096 - val_classification_loss: 2.0791 - val_loss: 2.8657 - val_regression_loss: 0.7827 - val_regression_mse: 0.7855\n",
            "Epoch 36/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9765 - classification_loss: 0.0816 - loss: 0.4044 - regression_loss: 0.3227 - regression_mse: 0.3227 - val_classification_accuracy: 0.6023 - val_classification_loss: 2.0980 - val_loss: 2.8692 - val_regression_loss: 0.7671 - val_regression_mse: 0.7693\n",
            "Epoch 37/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9736 - classification_loss: 0.0880 - loss: 0.4132 - regression_loss: 0.3252 - regression_mse: 0.3252 - val_classification_accuracy: 0.6073 - val_classification_loss: 2.0916 - val_loss: 2.8601 - val_regression_loss: 0.7685 - val_regression_mse: 0.7703\n",
            "Epoch 38/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9772 - classification_loss: 0.0820 - loss: 0.4067 - regression_loss: 0.3247 - regression_mse: 0.3247 - val_classification_accuracy: 0.6037 - val_classification_loss: 2.0474 - val_loss: 2.7972 - val_regression_loss: 0.7516 - val_regression_mse: 0.7531\n",
            "Epoch 39/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9806 - classification_loss: 0.0792 - loss: 0.4008 - regression_loss: 0.3216 - regression_mse: 0.3216 - val_classification_accuracy: 0.6064 - val_classification_loss: 2.0868 - val_loss: 2.8528 - val_regression_loss: 0.7636 - val_regression_mse: 0.7651\n",
            "Epoch 40/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - classification_accuracy: 0.9820 - classification_loss: 0.0733 - loss: 0.3892 - regression_loss: 0.3159 - regression_mse: 0.3159 - val_classification_accuracy: 0.6154 - val_classification_loss: 2.0968 - val_loss: 2.8663 - val_regression_loss: 0.7686 - val_regression_mse: 0.7704\n",
            "Epoch 41/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9789 - classification_loss: 0.0782 - loss: 0.3914 - regression_loss: 0.3132 - regression_mse: 0.3132 - val_classification_accuracy: 0.6019 - val_classification_loss: 2.0798 - val_loss: 2.8638 - val_regression_loss: 0.7857 - val_regression_mse: 0.7881\n",
            "Epoch 42/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9807 - classification_loss: 0.0736 - loss: 0.3889 - regression_loss: 0.3153 - regression_mse: 0.3153 - val_classification_accuracy: 0.6060 - val_classification_loss: 2.1395 - val_loss: 2.9138 - val_regression_loss: 0.7704 - val_regression_mse: 0.7726\n",
            "Epoch 43/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9781 - classification_loss: 0.0840 - loss: 0.3991 - regression_loss: 0.3151 - regression_mse: 0.3151 - val_classification_accuracy: 0.6141 - val_classification_loss: 2.0584 - val_loss: 2.8395 - val_regression_loss: 0.7782 - val_regression_mse: 0.7811\n",
            "Epoch 44/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9771 - classification_loss: 0.0886 - loss: 0.3995 - regression_loss: 0.3109 - regression_mse: 0.3109 - val_classification_accuracy: 0.6208 - val_classification_loss: 2.0843 - val_loss: 2.8644 - val_regression_loss: 0.7795 - val_regression_mse: 0.7815\n",
            "Epoch 45/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9827 - classification_loss: 0.0666 - loss: 0.3698 - regression_loss: 0.3032 - regression_mse: 0.3032 - val_classification_accuracy: 0.6168 - val_classification_loss: 2.0983 - val_loss: 2.8928 - val_regression_loss: 0.7903 - val_regression_mse: 0.7925\n",
            "Epoch 46/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9805 - classification_loss: 0.0693 - loss: 0.3759 - regression_loss: 0.3066 - regression_mse: 0.3066 - val_classification_accuracy: 0.6123 - val_classification_loss: 2.1403 - val_loss: 2.9342 - val_regression_loss: 0.7978 - val_regression_mse: 0.8005\n",
            "Epoch 47/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - classification_accuracy: 0.9806 - classification_loss: 0.0739 - loss: 0.3824 - regression_loss: 0.3084 - regression_mse: 0.3084 - val_classification_accuracy: 0.6041 - val_classification_loss: 2.1444 - val_loss: 2.9172 - val_regression_loss: 0.7753 - val_regression_mse: 0.7782\n",
            "Epoch 48/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9808 - classification_loss: 0.0666 - loss: 0.3715 - regression_loss: 0.3049 - regression_mse: 0.3049 - val_classification_accuracy: 0.6204 - val_classification_loss: 2.1417 - val_loss: 2.9592 - val_regression_loss: 0.8223 - val_regression_mse: 0.8249\n",
            "Epoch 49/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9825 - classification_loss: 0.0704 - loss: 0.3732 - regression_loss: 0.3028 - regression_mse: 0.3028 - val_classification_accuracy: 0.6078 - val_classification_loss: 2.2410 - val_loss: 2.9960 - val_regression_loss: 0.7570 - val_regression_mse: 0.7593\n",
            "Epoch 50/50\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - classification_accuracy: 0.9840 - classification_loss: 0.0668 - loss: 0.3702 - regression_loss: 0.3034 - regression_mse: 0.3034 - val_classification_accuracy: 0.6041 - val_classification_loss: 2.2044 - val_loss: 2.9605 - val_regression_loss: 0.7605 - val_regression_mse: 0.7624\n"
          ]
        }
      ],
      "source": [
        "modelNLP.fit(\n",
        "    X_train, [Y_train_reg, to_categorical(Y_train_class, num_classes = nClass)],\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "\n",
        ")\n",
        "\n",
        "modelNLP.save(\"RNNModel.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "orLCo9OxH4Iv",
      "metadata": {
        "id": "orLCo9OxH4Iv"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "049a6811",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "049a6811",
        "outputId": "32bb8235-170a-4d1d-f4c7-017d54b665a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   2 4041 4201  498 9873    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    0]\n"
          ]
        }
      ],
      "source": [
        "df_test = pd.read_csv(\"trac2_CONVT_dev.csv\")\n",
        "df_test[\"EmotionalPolarity\"] = np.ceil(df_test['EmotionalPolarity'])\n",
        "columnsTest = df_test[\"text\"]\n",
        "cleanColumn = []\n",
        "listSentenceTest = []\n",
        "\n",
        "for column in columnsTest:\n",
        "    cleanColumn = clean_text(column)\n",
        "    listSentenceTest.append(cleanColumn)\n",
        "listWordVectorTest = []\n",
        "for sentence in listSentenceTest:\n",
        "    listWord = sentence.split(\" \")\n",
        "    if \"\" in listWord:\n",
        "        listWord.remove(\"\")\n",
        "    listWordVectorTest.append(listWord)\n",
        "listWordVectorTest[0:5]\n",
        "\n",
        "listSentencePadTest = padSentence(listWordVectorTest)\n",
        "wordTensorTest = convertToTensor(listSentencePadTest)\n",
        "X_test = np.array(wordTensorTest)\n",
        "print(wordTensorTest[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "-cWLboeNrBuc",
      "metadata": {
        "id": "-cWLboeNrBuc"
      },
      "outputs": [],
      "source": [
        "Y_test_reg, Y_test_class = processOutput(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "Vx_McK7RrEe5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "id": "Vx_McK7RrEe5",
        "outputId": "55123604-b15c-4fa3-ce6c-ba45eff7e06f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE per output: [0.55666727 1.14004515]\n",
            "RMSE per output: [0.74610138 1.06772897]\n",
            "MAE per output: [0.5868087  0.87731581]\n",
            "Precision: 0.6051\n",
            "Recall:    0.5990\n",
            "F1 Score:  0.5963\n",
            "Accuracy:  0.5990\n"
          ]
        }
      ],
      "source": [
        "# Predict Y_pred and compare with Y_test, and build confusion matrix as well as compute stats\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "modelNLP = load_model(\"RNNModel.keras\")\n",
        "\n",
        "y_pred = modelNLP.predict(X_test)\n",
        "y_reg_pred = y_pred[0]\n",
        "y_class_pred = np.argmax(y_pred[1], axis=1)\n",
        "\n",
        "\n",
        "mse = mean_squared_error(Y_test_reg, y_reg_pred, multioutput='raw_values')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "mae = mean_absolute_error(Y_test_reg, y_reg_pred, multioutput='raw_values')\n",
        "\n",
        "cm = confusion_matrix(Y_test_class, y_class_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()\n",
        "\n",
        "precision = precision_score(Y_test_class, y_class_pred, average = \"weighted\")\n",
        "\n",
        "recall = recall_score(Y_test_class, y_class_pred, average = \"weighted\")\n",
        "\n",
        "f1 = f1_score(Y_test_class, y_class_pred, average = \"weighted\")\n",
        "\n",
        "accuracy = accuracy_score(Y_test_class, y_class_pred)\n",
        "\n",
        "print(\"MSE per output:\", mse)\n",
        "\n",
        "print(\"RMSE per output:\", rmse)\n",
        "\n",
        "print(\"MAE per output:\", mae)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n",
        "\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "e405726a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   2 9832 4322 8101 1147 1298 5022 2512 4607 5334 8729 5624 4271 2535\n",
            " 4869 9623 8881 8778 6010 3262   18 8789  533    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    0]\n"
          ]
        }
      ],
      "source": [
        "df_infer = pd.read_csv(\"trac2_CONVT_test.csv\")\n",
        "\n",
        "columnsInfer = df_infer[\"text\"]\n",
        "cleanColumn = []\n",
        "listSentenceInfer = []\n",
        "\n",
        "for column in columnsInfer:\n",
        "    cleanColumn = clean_text(column)\n",
        "    listSentenceInfer.append(cleanColumn)\n",
        "listWordVectorInfer = []\n",
        "for sentence in listSentenceInfer:\n",
        "    listWord = sentence.split(\" \")\n",
        "    if \"\" in listWord:\n",
        "        listWord.remove(\"\")\n",
        "    listWordVectorInfer.append(listWord)\n",
        "\n",
        "listSentencePadInfer = padSentence(listWordVectorInfer)\n",
        "wordTensorInfer = convertToTensor(listSentencePadInfer)\n",
        "X_infer = np.array(wordTensorInfer)\n",
        "print(wordTensorInfer[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "c10d8f6f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step\n"
          ]
        }
      ],
      "source": [
        "ID = df_infer[\"id\"]\n",
        "\n",
        "y_infer = modelNLP.predict(X_infer)\n",
        "\n",
        "y_reg_infer = y_infer[0]\n",
        "y_class_infer = np.argmax(y_infer[1], axis=1)\n",
        "\n",
        "\n",
        "df_pred = pd.DataFrame({\n",
        "    \"ID\": ID,\n",
        "    \"Emotion\": y_reg_infer[:, 0],\n",
        "    \"EmotionalPolarity\": y_class_infer,\n",
        "    \"Empathy\": y_reg_infer[:, 1]\n",
        "})\n",
        "\n",
        "\n",
        "df_pred.to_csv(\"predictions_rnn.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
